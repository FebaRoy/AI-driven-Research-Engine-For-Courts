{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2e64cc2c-62ab-4b22-adca-842dcf2f5025",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\ASUS\\anaconda3\\envs\\new_env\\lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import nltk\n",
    "import docx\n",
    "import torch\n",
    "import queue\n",
    "import spacy\n",
    "import PyPDF2\n",
    "import joblib\n",
    "import cohere\n",
    "import logging\n",
    "import tempfile\n",
    "import warnings\n",
    "import threading\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tkinter as tk\n",
    "from tkinter import ttk\n",
    "from sklearn.svm import SVC\n",
    "from bs4 import BeautifulSoup\n",
    "from pdfminer.high_level import extract_text\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from nltk.tokenize.texttiling import TextTilingTokenizer\n",
    "from tkinter import filedialog, messagebox, Text, Scrollbar\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from transformers import pipeline, BertTokenizerFast, BertForTokenClassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e537ead9-8430-4967-ab7c-0af4f04d0b78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the dataset\n",
    "dataset_path = r\"C:\\Users\\ASUS\\OneDrive\\Documents\\Semester 9\\Mini Project\\Cases.csv\"\n",
    "cases_df = pd.read_csv(dataset_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ca27954d-f98e-4a5a-a639-13a44b59dbed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b092ba71e684316b2b79e87b3ef6321",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/3.51k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Initializing the SentenceTransformer model for semantic embedding\n",
    "embedding_model = SentenceTransformer('paraphrase-MiniLM-L6-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4c62fa44-e707-4651-b6cd-b62909589fde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the fine-tuned model and tokenizer\n",
    "model = BertForTokenClassification.from_pretrained('./ner_model')\n",
    "tokenizer = BertTokenizerFast.from_pretrained('./ner_model')\n",
    "ner_pipeline = pipeline(\"ner\", model=model, tokenizer=tokenizer, aggregation_strategy=\"simple\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e779f6c4-b7c8-4bb6-b083-b206842876db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing models and APIs\n",
    "co = cohere.Client(os.environ.get(\"2thOmTVyrX5uwYuSieF1AhVKxRwP3UuZxakIiXc3\"))\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"law-ai/InLegalBERT\")\n",
    "model = AutoModel.from_pretrained(\"law-ai/InLegalBERT\")\n",
    "tiling_tokenizer = TextTilingTokenizer()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "818651fe-6930-4ab0-b46a-633e5e8589c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_queue = queue.Queue()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7fedb07f-d951-421b-9b39-8ed75012a1e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Suppressing warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "096484c2-f11f-4b84-9d4d-c5a10fe92fc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def upload_file():\n",
    "    file_path = filedialog.askopenfilename(\n",
    "        title=\"Select Case File\",\n",
    "        filetypes=[(\"PDF Files\", \"*.pdf\"), (\"Word Documents\", \"*.docx\"), (\"Text Files\", \"*.txt\")]\n",
    "    )\n",
    "    if file_path:\n",
    "        threading.Thread(target=process_file, args=(file_path,), daemon=True).start()\n",
    "        start_progress_bar()\n",
    "    else:\n",
    "        messagebox.showinfo(\"Info\", \"No file selected.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d7bb8459-2b66-49ed-ba5d-9ee22f3a876c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_file(file_path):\n",
    "    try:\n",
    "        logging.info(f\"File Selected: {file_path}\")\n",
    "        file_label.config(text=f\"Selected File Path: {file_path}\")\n",
    "\n",
    "        if file_path.endswith(\".pdf\"):\n",
    "            content = extract_pdf(file_path)\n",
    "        elif file_path.endswith(\".docx\"):\n",
    "            content = extract_docx(file_path)\n",
    "        elif file_path.endswith(\".txt\"):\n",
    "            content = extract_txt(file_path)\n",
    "        else:\n",
    "            messagebox.showerror(\"Error\", \"Unsupported file format.\")\n",
    "            return\n",
    "        display_content(content)\n",
    "        entities = extract_entities(content)\n",
    "        unique_entities = list({(ent['word'], ent['entity_group']) for ent in entities})\n",
    "        print(\"Extracted Entities:\", unique_entities)\n",
    "\n",
    "        \n",
    "        search_query = \" \".join([ent[0] for ent in unique_entities])\n",
    "        case_links = search_indian_kanoon(search_query)\n",
    "        print(\"Found Case Links:\", case_links)\n",
    "\n",
    "        \n",
    "        for i in range(min(len(unique_entities), len(case_links))):\n",
    "            ent = unique_entities[i]\n",
    "            link = case_links[i]\n",
    "            print(f\"{ent[0]} : {link}\")\n",
    "\n",
    "        # Predict case details\n",
    "        preceding, legal_laws, result = predict_case_details(content)\n",
    "        print(f\"Predicted Preceding: {preceding}\")\n",
    "        print(f\"Predicted Legal Laws: {legal_laws}\")\n",
    "        print(f\"Predicted Result: {result}\")\n",
    "\n",
    "\n",
    "    except Exception as e:\n",
    "        logging.error(f\"An error occurred: {e}\")\n",
    "        messagebox.showerror(\"Error\", f\"An error occurred: {e}\")\n",
    "    \n",
    "    finally:\n",
    "        stop_progress_bar()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fc2f27e1-bbf6-4f5e-9b31-266f834073ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_gui():\n",
    "    try:\n",
    "        while not result_queue.empty():\n",
    "            content = result_queue.get()\n",
    "            display_content(content)\n",
    "    except Exception as e:\n",
    "        messagebox.showerror(\"Error\", f\"An error occurred while updating GUI: {e}\")\n",
    "    finally:\n",
    "        root.after(100, update_gui)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "752cf5f3-d33d-4f71-8e05-5c4e9d6b8c3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_pdf(pdf_path_var):\n",
    "    \"\"\"Open file dialog to select a PDF and display its path.\"\"\"\n",
    "    file_path = filedialog.askopenfilename(filetypes=[(\"PDF Files\", \"*.pdf\")])\n",
    "    print(f\"Selected file path: {file_path}\")  # Debugging step\n",
    "    \n",
    "    if file_path:  # Check if a file was selected\n",
    "        pdf_path_var.set(file_path)\n",
    "    else:\n",
    "        print(\"No file selected!\")  # Debugging step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1b2bcf5b-5e5a-4003-a1db-e08e964bfba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_text_from_pdf(pdf_path):\n",
    "    return extract_text(pdf_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "76196c6f-565a-442c-bd0e-ce4d3dd0f875",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_engine(pdf_path_var, query_entry, response_text):\n",
    "    pdf_path = pdf_path_var.get()\n",
    "    query = query_entry.get(\"1.0\", tk.END).strip()\n",
    "    \n",
    "    if not pdf_path or not query:\n",
    "        messagebox.showerror(\"Error\", \"Please upload a PDF and enter a query.\")\n",
    "        return\n",
    "\n",
    "    try:\n",
    "        response = process_pdf_and_generate_response(pdf_path, query)\n",
    "        response_text.delete(\"1.0\", tk.END)\n",
    "        response_text.insert(tk.END, response)\n",
    "    except Exception as e:\n",
    "        messagebox.showerror(\"Error\", str(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9b0c54ce-a731-420e-98e4-f1a8dcc1d7ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_pdf_and_generate_response(pdf_path, query): \n",
    "    \n",
    "    # Extract text from the PDF\n",
    "    document_text = extract_text_from_pdf(pdf_path)\n",
    "    \n",
    "    # Tokenize and get document embeddings\n",
    "    text_chunks = tiling_tokenizer.tokenize(document_text)\n",
    "    document_embeddings = get_bert_embeddings(text_chunks)\n",
    "    \n",
    "    prompt = f\"You are an AI-driven research engine for commercial courts. Given the legal document: '{document_text[:2000]}', answer the query: '{query}'\"\n",
    "    response = generate_response(prompt, document_embeddings)\n",
    "    \n",
    "    # Check if the query mentions predictions or related cases\n",
    "    if \"prediction\" in query.lower() or \"preceding\" in query.lower() or \"legal_laws\" in query.lower() or \"result\" in query.lower():\n",
    "        predictions = predict_case_details(document_text)\n",
    "        response += \"\\n\\nPredictions: \" + str(predictions)\n",
    "    \n",
    "    if \"related cases\" in query.lower() or \"similar cases\" in query.lower():\n",
    "        related_cases = search_indian_kanoon(query)\n",
    "        response += \"\\n\\nRelated Cases: \" + str(related_cases)\n",
    "    \n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8ab0f512-6c11-4a1b-8755-0492796297c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_response(prompt, embeddings):\n",
    "    aggregated_embedding = np.mean([np.mean(embed) for embed in embeddings])\n",
    "    embedding_str = f\"Embedding summary: {aggregated_embedding:.2f}\"\n",
    "    full_prompt = f\"{embedding_str}\\n\\n{prompt}\"\n",
    "    try:\n",
    "        response = co.chat(\n",
    "            model=\"command-xlarge-nightly\",\n",
    "            message=full_prompt,\n",
    "            max_tokens=750\n",
    "        )\n",
    "        return response.text.strip()\n",
    "    except cohere.error.CohereError as e:\n",
    "        return f\"An error occurred: {str(e)}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9d92070c-333e-4185-9c5a-1213d5a344ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bert_embeddings(texts):\n",
    "    embeddings_list = []\n",
    "    for text in texts:\n",
    "        inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, max_length=512)\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**inputs)\n",
    "        embeddings = outputs.last_hidden_state[:, 0, :].squeeze().numpy()\n",
    "        embeddings_list.append(embeddings)\n",
    "    return embeddings_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d0aa129d-17e0-4e7c-bb38-1bc9abf11cdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def open_research_page():\n",
    "    # Root window\n",
    "    root = tk.Tk()\n",
    "    root.title(\"AI Research Engine for Legal Documents\")\n",
    "    root.geometry(\"850x700\")\n",
    "    root.configure(bg=\"#4CAF50\")\n",
    "\n",
    "    # Fonts\n",
    "    title_font = (\"Arial\", 18, \"bold\")\n",
    "    label_font = (\"Arial\", 12)\n",
    "    button_font = (\"Arial\", 11)\n",
    "\n",
    "    # Frames\n",
    "    title_frame = tk.Frame(root, bg=\"#4CAF50\", height=60)\n",
    "    title_frame.pack(fill=tk.X)\n",
    "\n",
    "    content_frame = tk.Frame(root, bg=\"#f5f5f5\", padx=20, pady=20)\n",
    "    content_frame.pack(fill=tk.BOTH, expand=True)\n",
    "\n",
    "    footer_frame = tk.Frame(root, bg=\"#4CAF50\", height=40)\n",
    "    footer_frame.pack(fill=tk.X)\n",
    "\n",
    "    # Title Label\n",
    "    title_label = tk.Label(\n",
    "        title_frame,\n",
    "        text=\"AI-Driven Research Engine for Commercial Courts\",\n",
    "        font=title_font,\n",
    "        bg=\"#4CAF50\",\n",
    "        fg=\"#ffffff\"\n",
    "    )\n",
    "    title_label.pack(pady=10)\n",
    "\n",
    "    # File Upload Section\n",
    "    pdf_path_var = tk.StringVar()\n",
    "    file_frame = tk.LabelFrame(content_frame, text=\"Upload Document\", font=label_font, bg=\"#f5f5f5\", padx=10, pady=10)\n",
    "    file_frame.pack(fill=\"x\", pady=10)\n",
    "\n",
    "    file_entry = ttk.Entry(file_frame, textvariable=pdf_path_var, width=60, state='readonly')\n",
    "    file_entry.grid(row=0, column=0, padx=5, pady=5)\n",
    "\n",
    "    browse_button = ttk.Button(file_frame, text=\"Browse\", command=lambda: select_pdf(pdf_path_var))\n",
    "    browse_button.grid(row=0, column=1, padx=5, pady=5)\n",
    "\n",
    "    # Query Input Section\n",
    "    query_frame = tk.LabelFrame(content_frame, text=\"Enter Query\", font=label_font, bg=\"#f5f5f5\", padx=10, pady=10)\n",
    "    query_frame.pack(fill=\"x\", pady=10)\n",
    "\n",
    "    query_entry = Text(query_frame, height=5, wrap=tk.WORD, font=(\"Arial\", 10))\n",
    "    query_entry.pack(fill=\"x\", padx=5, pady=5)\n",
    "\n",
    "    # Run Button\n",
    "    run_button = ttk.Button(content_frame, text=\"Generate Response\", command=lambda: run_engine(pdf_path_var, query_entry, response_text))\n",
    "    run_button.pack(pady=10)\n",
    "\n",
    "    # Response Display Section\n",
    "    response_frame = tk.LabelFrame(content_frame, text=\"Response\", font=label_font, bg=\"#f5f5f5\", padx=10, pady=10)\n",
    "    response_frame.pack(fill=\"both\", expand=True, pady=10)\n",
    "\n",
    "    response_text = Text(response_frame, wrap=tk.WORD, font=(\"Arial\", 10), height=15)\n",
    "    response_text.pack(fill=\"both\", expand=True, padx=5, pady=5)\n",
    "\n",
    "    response_scrollbar = Scrollbar(response_frame, command=response_text.yview)\n",
    "    response_scrollbar.pack(side=tk.RIGHT, fill=tk.Y)\n",
    "    response_text.config(yscrollcommand=response_scrollbar.set)\n",
    "\n",
    "    # Footer Label\n",
    "    footer_label = tk.Label(\n",
    "        footer_frame,\n",
    "        text=\"© 2024 AI Research Engine\",\n",
    "        font=(\"Arial\", 10),\n",
    "        bg=\"#4CAF50\",\n",
    "        fg=\"#ffffff\"\n",
    "    )\n",
    "    footer_label.pack(pady=10)\n",
    "\n",
    "    # Main loop to run the Tkinter application\n",
    "    root.mainloop()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "055ef8b2-7f8c-4f9f-bf7c-9c4c82d497f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_content(content):\n",
    "    def start_research():\n",
    "        open_research_page()\n",
    "        \n",
    "    def show_predictions():\n",
    "        # Predict case details only when the button/key is pressed\n",
    "        preceding, legal_laws, result = predict_case_details(content)\n",
    "        predictions_summary = f\"Preceding Case:\\n{preceding}\\n\\nLegal Laws:\\n{legal_laws}\\n\\nResult:\\n{result}\\n\"\n",
    "\n",
    "        predictions_window = tk.Toplevel(content_window)\n",
    "        predictions_window.title(\"Case Predictions\")\n",
    "        predictions_area = Text(predictions_window, wrap='word')\n",
    "        predictions_area.insert('1.0', predictions_summary)\n",
    "        predictions_area.config(state='disabled')\n",
    "        predictions_area.pack(expand=True, fill='both')\n",
    "    \n",
    "    content_window = tk.Toplevel()\n",
    "    content_window.title(\"Extracted Content\")\n",
    "    text_area = Text(content_window, wrap='word')\n",
    "    text_area.insert('1.0', \"Extracted Content:\\n\\n\" + content + \"\\n\\n\")\n",
    "    text_area.config(state='disabled')\n",
    "    text_area.pack(expand=True, fill='both')\n",
    "    content_window.geometry(\"600x500\")\n",
    "    \n",
    "    # Button to show predictions\n",
    "    predict_btn = tk.Button(content_window, text=\"Show Predictions\", command=show_predictions, bg=\"#4CAF50\", fg=\"white\", font=(\"Arial\", 12))\n",
    "    predict_btn.pack(pady=10)\n",
    "    \n",
    "    # Bind the 'p' key to show predictions\n",
    "    content_window.bind('<p>', lambda event: show_predictions())\n",
    "    \n",
    "    # Button to start research\n",
    "    research_btn = tk.Button(content_window, text=\"Start Research\", command=start_research, bg=\"#008CBA\", fg=\"white\", font=(\"Arial\", 12))\n",
    "    research_btn.pack(pady=10)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d4e90c9b-66f5-4b6b-a1f1-cc71c6ea5a5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_pdf(file_path):\n",
    "    print(f\"Processing PDF: {file_path}\")\n",
    "    content = \"\"\n",
    "    try:\n",
    "        with open(file_path, \"rb\") as file:\n",
    "            reader = PyPDF2.PdfReader(file)\n",
    "            for page in reader.pages:\n",
    "                text = page.extract_text()\n",
    "                if text:\n",
    "                    content += text + \"\\n\"\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing PDF: {e}\")\n",
    "    return content.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4b436275-0733-4b7c-a763-a2147af12bb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_docx(file_path):\n",
    "    print(f\"Processing DOCX: {file_path}\")\n",
    "    content = \"\"\n",
    "    try:\n",
    "        doc = docx.Document(file_path)\n",
    "        for paragraph in doc.paragraphs:\n",
    "            content += paragraph.text + \"\\n\"\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing DOCX: {e}\")\n",
    "    return content.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d2939833-afd9-4a6c-a9b4-70e803745012",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_txt(file_path):\n",
    "    print(f\"Processing TXT: {file_path}\")\n",
    "    content = \"\"\n",
    "    try:\n",
    "        with open(file_path, 'r', encoding='utf-8') as file:\n",
    "            content = file.read()\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing TXT: {e}\")\n",
    "    return content.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "04685771-8499-41d1-8ca9-9905df31b2d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_entities(text):\n",
    "    try:\n",
    "        entities = ner_pipeline(text)\n",
    "        return entities\n",
    "    except Exception as e:\n",
    "        print(f\"Error extracting entities: {e}\")\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f88cf765-6d22-4956-aa0d-759575aab2b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_indian_kanoon(query_text):\n",
    "    query_embedding = embedding_model.encode([query_text])\n",
    "\n",
    "    case_descriptions = cases_df['Case_Title'].tolist()\n",
    "    case_embeddings = embedding_model.encode(case_descriptions)\n",
    "\n",
    "    similarities = cosine_similarity(query_embedding, case_embeddings)\n",
    "\n",
    "    top_n = 5\n",
    "    top_n_indices = similarities[0].argsort()[-top_n:][::-1]\n",
    "\n",
    "    case_matches = []\n",
    "    for idx in top_n_indices:\n",
    "            case_matches.append({\n",
    "                'Case_Title': cases_df.iloc[idx]['Case_Title'],\n",
    "                'Similarity': similarities[0][idx]\n",
    "        })\n",
    "    return case_matches\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f58d3834-ca88-4654-8aa5-cfc4d171c17d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model training complete and saved!\n"
     ]
    }
   ],
   "source": [
    "# Combine relevant columns for features\n",
    "cases_df['Combined_Text'] = cases_df[['Case_Title', 'Citation', 'Court', \n",
    "                                      'Judgement_Date', 'Judges', 'Petitioner',\n",
    "                                      'Respondent', 'Bench']].apply(lambda x: ' '.join(x.astype(str)), axis=1)\n",
    "\n",
    "# Define features (X) and targets (y)\n",
    "X = cases_df['Combined_Text']\n",
    "y = cases_df[['Preceding', 'Legal_Laws', 'Result']]\n",
    "\n",
    "# TF-IDF vectorization\n",
    "tfidf = TfidfVectorizer(max_features=5000)\n",
    "X_vectorized = tfidf.fit_transform(X)\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_vectorized, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# MultiOutputClassifier with Random Forest\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "multi_rf = MultiOutputClassifier(rf_model)\n",
    "multi_rf.fit(X_train, y_train)\n",
    "\n",
    "# Save the trained model and vectorizer\n",
    "joblib.dump(multi_rf, 'random_forest_model.pkl')\n",
    "joblib.dump(tfidf, 'tfidf_vectorizer.pkl')\n",
    "\n",
    "print(\"Model training complete and saved!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "83500942-c0a5-4ce0-a73a-a3835cb795db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_case_details(content):\n",
    "    \"\"\"\n",
    "    Predict Preceding, Legal Laws, and Result based on uploaded content.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        multi_rf = joblib.load('random_forest_model.pkl')\n",
    "        tfidf = joblib.load('tfidf_vectorizer.pkl')\n",
    "        content_vector = tfidf.transform([content])\n",
    "        predictions = multi_rf.predict(content_vector)\n",
    "        preceding, legal_laws, result = predictions[0]\n",
    "\n",
    "        return preceding, legal_laws, result\n",
    "    except Exception as e:\n",
    "        print(f\"Prediction error: {e}\")\n",
    "        return None, None, None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b968ef9a-98ee-4c88-bc43-379fcbf13548",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_query_details(query_text):\n",
    "    \"\"\"\n",
    "    Predict Precedings, Legal Laws, and Result based on the search query.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Load model and vectorizer\n",
    "        multi_rf = joblib.load('random_forest_model.pkl')\n",
    "        tfidf = joblib.load('tfidf_vectorizer.pkl')\n",
    "\n",
    "        # Vectorize the query text\n",
    "        query_vector = tfidf.transform([query_text])\n",
    "\n",
    "        # Predict\n",
    "        predictions = multi_rf.predict(query_vector)\n",
    "        preceding, legal_laws, result = predictions[0]\n",
    "\n",
    "        return preceding, legal_laws, result\n",
    "    except Exception as e:\n",
    "        print(f\"Prediction error for query: {e}\")\n",
    "        return None, None, None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "aa05adf6-75e1-44a3-83ff-001e0ac778aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize_case_titles():\n",
    "    case_titles = cases_df['Case_Title'].tolist()\n",
    "\n",
    "    # Use SentenceTransformer to get embeddings\n",
    "    model = SentenceTransformer('paraphrase-MiniLM-L6-v2')\n",
    "    case_vectors = model.encode(case_titles)\n",
    "\n",
    "    return case_titles, case_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "67e69508-df48-4338-9b4c-545d41f82508",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_related_cases(query, case_titles, case_vectors, top_n=5):\n",
    "    # Vectorize the query using SentenceTransformer\n",
    "    model = SentenceTransformer('paraphrase-MiniLM-L6-v2')\n",
    "    query_vector = model.encode([query])\n",
    "\n",
    "    # Perform KNN search\n",
    "    knn = NearestNeighbors(n_neighbors=top_n, metric='cosine')\n",
    "    knn.fit(case_vectors)\n",
    "    distances, indices = knn.kneighbors(query_vector)\n",
    "\n",
    "    # Get the most similar case titles based on the indices\n",
    "    related_cases = [case_titles[idx] for idx in indices[0]]\n",
    "    return related_cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "596cbe5b-2cf7-4c0c-9068-0641d193fdf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def start_progress_bar():\n",
    "    progress_bar.pack(pady=10)\n",
    "    progress_bar.start(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d6634991-25e9-46c4-94c1-c0fa4a5eec4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stop_progress_bar():\n",
    "    progress_bar.stop()\n",
    "    progress_bar.pack_forget()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2e4dcaff-f9c0-4f1a-a89c-27597cc35594",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_entities():\n",
    "    query = search_entry.get()\n",
    "    if query:\n",
    "        threading.Thread(target=process_search, args=(query,), daemon=True).start()\n",
    "        start_progress_bar()\n",
    "    else:\n",
    "        messagebox.showinfo(\"Info\", \"Please enter a search term.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2a981596-90c0-470c-9fbc-3a64f238c6c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_search_results(case_links, query_text):\n",
    "    results_window = tk.Toplevel()\n",
    "    results_window.title(\"Search Results\")\n",
    "    results_window.geometry(\"600x500\")\n",
    "    text_area = Text(results_window, wrap='word')\n",
    "    content = \"Top Similar Cases Based on Semantic Search:\\n\\n\"\n",
    "    for link in case_links:\n",
    "        content += f\"{link['Case_Title']} (Similarity: {link['Similarity']:.2f})\\n\"\n",
    "    text_area.insert('1.0', content)\n",
    "    text_area.config(state='disabled')\n",
    "    text_area.pack(expand=True, fill='both')\n",
    "\n",
    "    # Add Predict button\n",
    "    predict_button = tk.Button(\n",
    "        results_window,\n",
    "        text=\"Predict\",\n",
    "        command=lambda: show_predictions_window(query_text), \n",
    "        bg=\"#4CAF50\", \n",
    "        fg=\"white\", \n",
    "        font=(\"Arial\", 12)\n",
    "    )\n",
    "    predict_button.pack(pady=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ac4ca224-d78e-4078-b279-e2e6cdb51179",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_predictions_window(query_text):\n",
    "    try:\n",
    "        preceding, legal_laws, result = predict_query_details(query_text)\n",
    "        predictions_window = tk.Toplevel()\n",
    "        predictions_window.title(\"Query Predictions\")\n",
    "        predictions_window.geometry(\"600x400\")\n",
    "\n",
    "        text_area = Text(predictions_window, wrap='word')\n",
    "        predictions_summary = (\n",
    "            f\"Search Query Predictions:\\n\\n\"\n",
    "            f\"Preceding Case:\\n{preceding if preceding else 'N/A'}\\n\\n\"\n",
    "            f\"Legal Laws:\\n{legal_laws if legal_laws else 'N/A'}\\n\\n\"\n",
    "            f\"Result:\\n{result if result else 'N/A'}\\n\"\n",
    "        )\n",
    "        text_area.insert('1.0', predictions_summary)\n",
    "        text_area.config(state='disabled')\n",
    "        text_area.pack(expand=True, fill='both')\n",
    "\n",
    "    except Exception as e:\n",
    "        messagebox.showerror(\"Error\", f\"An error occurred while displaying predictions: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "baa606ca-72b0-4941-8ab7-98014fbea907",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_search(query):\n",
    "    try:\n",
    "        case_links = search_indian_kanoon(query)\n",
    "        preceding, legal_laws, result = predict_query_details(query)\n",
    "        print(f\"Predicted Preceding: {preceding}\")\n",
    "        print(f\"Predicted Legal Laws: {legal_laws}\")\n",
    "        print(f\"Predicted Result: {result}\")\n",
    "        display_search_results(case_links,query)\n",
    "    except Exception as e:\n",
    "        messagebox.showerror(\"Error\", f\"An error occurred during the search: {e}\")\n",
    "    finally:\n",
    "        stop_progress_bar()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a9d3dccc-ed91-4e2b-8316-2dd706f4f05c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the Tkinter GUI\n",
    "root = tk.Tk()\n",
    "root.title(\"File Upload and Content Extractor\")\n",
    "root.geometry(\"600x400\")\n",
    "root.config(bg=\"#f0f0f0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "aff8a90d-589e-4e62-bd8c-51ec599dceb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "instruction_label = tk.Label(root, text=\"Upload the case file as .pdf, .docx or .txt\",\n",
    "                               bg=\"#f0f0f0\", font=(\"Arial\", 12))\n",
    "instruction_label.pack(pady=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "808e5ee0-de9d-4008-bed1-09c0ca7b5573",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entry for search term\n",
    "search_entry = tk.Entry(root, width=50, font=(\"Arial\", 12))\n",
    "search_entry.pack(pady=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d910e457-84ab-4572-ae97-c38768dc3edf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Search button\n",
    "search_btn = tk.Button(root, text=\"Search\", command=search_entities, width=20, bg=\"#4CAF50\", fg=\"white\", font=(\"Arial\", 12))\n",
    "search_btn.pack(pady=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ec211e0a-8440-4002-a7d4-ecfa00ecf523",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Frame for the upload button\n",
    "frame = tk.Frame(root, bg=\"#ffffff\", bd=2, relief=tk.GROOVE)\n",
    "frame.pack(pady=20, padx=10, fill='both', expand=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "fefeea23-505f-4484-8daf-19f7e5b79dc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "upload_btn = tk.Button(frame, text=\"Upload File\", command=upload_file, width=20, bg=\"#4CAF50\", fg=\"white\", font=(\"Arial\", 12))\n",
    "upload_btn.pack(pady=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f4b3d78e-35db-4b22-b572-521114210843",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label to display selected file path\n",
    "file_label = tk.Label(frame, text=\"Selected File Path: \", bg=\"#f0f0f0\", font=(\"Arial\", 10))\n",
    "file_label.pack(pady=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e2f48468-4f7c-4a96-872c-5d3f137ee8b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Progress bar (initially hidden)\n",
    "progress_bar = ttk.Progressbar(root, orient=\"horizontal\", mode=\"indeterminate\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "77ec9eb4-7a8e-47df-9f37-daf497a05efd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start the Tkinter event loop\n",
    "root.mainloop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "34cb334c-6223-433c-bd80-199518f42d91",
   "metadata": {},
   "outputs": [],
   "source": [
    "def open_research_page():\n",
    "    import warnings\n",
    "    warnings.filterwarnings('ignore')\n",
    "\n",
    "    import os\n",
    "    import tempfile\n",
    "    import tkinter as tk\n",
    "    from tkinter import filedialog, messagebox, Text, Scrollbar\n",
    "    from tkinter import ttk  # For themed widgets\n",
    "\n",
    "    import torch\n",
    "    import numpy as np\n",
    "    import cohere\n",
    "    import spacy\n",
    "    from nltk.tokenize import word_tokenize\n",
    "    from nltk import pos_tag\n",
    "    from pdfminer.high_level import extract_text\n",
    "    from nltk.tokenize.texttiling import TextTilingTokenizer\n",
    "\n",
    "    from transformers import AutoTokenizer, AutoModel\n",
    "\n",
    "    import nltk\n",
    "\n",
    "    # Initialize models and APIs\n",
    "    co = cohere.Client(os.environ.get(\"2thOmTVyrX5uwYuSieF1AhVKxRwP3UuZxakIiXc3\"))\n",
    "    nlp = spacy.load(\"en_core_web_sm\")\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\"law-ai/InLegalBERT\")\n",
    "    model = AutoModel.from_pretrained(\"law-ai/InLegalBERT\")\n",
    "    tiling_tokenizer = TextTilingTokenizer()\n",
    "\n",
    "    # Functions\n",
    "    def generate_response(prompt, embeddings):\n",
    "        aggregated_embedding = np.mean([np.mean(embed) for embed in embeddings])\n",
    "        embedding_str = f\"Embedding summary: {aggregated_embedding:.2f}\"\n",
    "        full_prompt = f\"{embedding_str}\\n\\n{prompt}\"\n",
    "        \n",
    "        try:\n",
    "            response = co.chat(\n",
    "                model=\"command-xlarge-nightly\",\n",
    "                message=full_prompt,\n",
    "                max_tokens=750\n",
    "            )\n",
    "            return response.text.strip()\n",
    "        except cohere.error.CohereError as e:\n",
    "            return f\"An error occurred: {str(e)}\"\n",
    "\n",
    "    def extract_text_from_pdf(pdf_path):\n",
    "        return extract_text(pdf_path)\n",
    "\n",
    "    def get_bert_embeddings(texts):\n",
    "        embeddings_list = []\n",
    "        for text in texts:\n",
    "            inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, max_length=512)\n",
    "            with torch.no_grad():\n",
    "                outputs = model(**inputs)\n",
    "            embeddings = outputs.last_hidden_state[:, 0, :].squeeze().numpy()\n",
    "            embeddings_list.append(embeddings)\n",
    "        return embeddings_list\n",
    "\n",
    "    def process_pdf_and_generate_response(pdf_path, query):\n",
    "        document_text = extract_text_from_pdf(pdf_path)\n",
    "        text_chunks = tiling_tokenizer.tokenize(document_text)\n",
    "        document_embeddings = get_bert_embeddings(text_chunks)\n",
    "        \n",
    "        prompt = f\"You are an AI-driven research engine for commercial courts. Given the legal document: '{document_text[:2000]}', answer the query: '{query}'\"\n",
    "        response = generate_response(prompt, document_embeddings)\n",
    "        return response\n",
    "\n",
    "    def select_pdf():\n",
    "        file_path = filedialog.askopenfilename(filetypes=[(\"PDF Files\", \"*.pdf\")])\n",
    "        pdf_path_var.set(file_path)\n",
    "\n",
    "    def run_engine():\n",
    "        pdf_path = pdf_path_var.get()\n",
    "        query = query_entry.get(\"1.0\", tk.END).strip()\n",
    "        if not pdf_path or not query:\n",
    "            messagebox.showerror(\"Error\", \"Please upload a PDF and enter a query.\")\n",
    "            return\n",
    "        \n",
    "        try:\n",
    "            response = process_pdf_and_generate_response(pdf_path, query)\n",
    "            response_text.delete(\"1.0\", tk.END)\n",
    "            response_text.insert(tk.END, response)\n",
    "        except Exception as e:\n",
    "            messagebox.showerror(\"Error\", str(e))\n",
    "\n",
    "    # Tkinter GUI\n",
    "    root = tk.Tk()\n",
    "    root.title(\"AI Research Engine for Legal Documents\")\n",
    "    root.geometry(\"850x700\")\n",
    "    root.configure(bg=\"#4CAF50\")\n",
    "\n",
    "    # Fonts\n",
    "    title_font = (\"Arial\", 18, \"bold\")\n",
    "    label_font = (\"Arial\", 12)\n",
    "    button_font = (\"Arial\", 11)\n",
    "\n",
    "    # Frames\n",
    "    title_frame = tk.Frame(root, bg=\"#4CAF50\", height=60)\n",
    "    title_frame.pack(fill=tk.X)\n",
    "\n",
    "    content_frame = tk.Frame(root, bg=\"#f5f5f5\", padx=20, pady=20)\n",
    "    content_frame.pack(fill=tk.BOTH, expand=True)\n",
    "\n",
    "    footer_frame = tk.Frame(root, bg=\"#4CAF50\", height=40)\n",
    "    footer_frame.pack(fill=tk.X)\n",
    "\n",
    "    # Title\n",
    "    title_label = tk.Label(\n",
    "        title_frame,\n",
    "        text=\"AI-Driven Research Engine for Commercial Courts\",\n",
    "        font=title_font,\n",
    "        bg=\"#4CAF50\",\n",
    "        fg=\"#ffffff\"\n",
    "    )\n",
    "    title_label.pack(pady=10)\n",
    "\n",
    "    # File Upload\n",
    "    pdf_path_var = tk.StringVar()\n",
    "    file_frame = tk.LabelFrame(content_frame, text=\"Upload Document\", font=label_font, bg=\"#f5f5f5\", padx=10, pady=10)\n",
    "    file_frame.pack(fill=\"x\", pady=10)\n",
    "\n",
    "    file_entry = ttk.Entry(file_frame, textvariable=pdf_path_var, width=60, state='readonly')\n",
    "    file_entry.grid(row=0, column=0, padx=5, pady=5)\n",
    "\n",
    "    browse_button = ttk.Button(file_frame, text=\"Browse\", command=select_pdf)\n",
    "    browse_button.grid(row=0, column=1, padx=5, pady=5)\n",
    "\n",
    "    # Query Input\n",
    "    query_frame = tk.LabelFrame(content_frame, text=\"Enter Query\", font=label_font, bg=\"#f5f5f5\", padx=10, pady=10)\n",
    "    query_frame.pack(fill=\"x\", pady=10)\n",
    "\n",
    "    query_entry = Text(query_frame, height=5, wrap=tk.WORD, font=(\"Arial\", 10))\n",
    "    query_entry.pack(fill=\"x\", padx=5, pady=5)\n",
    "\n",
    "    # Run Button\n",
    "    run_button = ttk.Button(content_frame, text=\"Generate Response\", command=run_engine)\n",
    "    run_button.pack(pady=10)\n",
    "\n",
    "    # Response Display\n",
    "    response_frame = tk.LabelFrame(content_frame, text=\"Response\", font=label_font, bg=\"#f5f5f5\", padx=10, pady=10)\n",
    "    response_frame.pack(fill=\"both\", expand=True, pady=10)\n",
    "\n",
    "    response_text = Text(response_frame, wrap=tk.WORD, font=(\"Arial\", 10), height=15)\n",
    "    response_text.pack(fill=\"both\", expand=True, padx=5, pady=5)\n",
    "\n",
    "    response_scrollbar = Scrollbar(response_frame, command=response_text.yview)\n",
    "    response_scrollbar.pack(side=tk.RIGHT, fill=tk.Y)\n",
    "    response_text.config(yscrollcommand=response_scrollbar.set)\n",
    "\n",
    "    # Footer\n",
    "    footer_label = tk.Label(\n",
    "        footer_frame,\n",
    "        text=\"© 2024 AI Research Engine\",\n",
    "        font=(\"Arial\", 10),\n",
    "        bg=\"#4CAF50\",\n",
    "        fg=\"#ffffff\"\n",
    "    )\n",
    "    footer_label.pack(pady=10)\n",
    "\n",
    "    # Mainloop\n",
    "    root.mainloop()\n",
    "open_research_page()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "ffab4204-24cf-4595-9994-88b97cd67d62",
   "metadata": {},
   "outputs": [
    {
     "ename": "ConnectError",
     "evalue": "[Errno 11001] getaddrinfo failed",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mgaierror\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32m~\\anaconda3\\envs\\new_env\\lib\\site-packages\\httpcore\\_exceptions.py:10\u001b[0m, in \u001b[0;36mmap_exceptions\u001b[1;34m(map)\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 10\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:  \u001b[38;5;66;03m# noqa: PIE786\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\new_env\\lib\\site-packages\\httpcore\\_backends\\sync.py:206\u001b[0m, in \u001b[0;36mSyncBackend.connect_tcp\u001b[1;34m(self, host, port, timeout, local_address, socket_options)\u001b[0m\n\u001b[0;32m    205\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m map_exceptions(exc_map):\n\u001b[1;32m--> 206\u001b[0m     sock \u001b[38;5;241m=\u001b[39m \u001b[43msocket\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_connection\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    207\u001b[0m \u001b[43m        \u001b[49m\u001b[43maddress\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    208\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    209\u001b[0m \u001b[43m        \u001b[49m\u001b[43msource_address\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msource_address\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    210\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    211\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m option \u001b[38;5;129;01min\u001b[39;00m socket_options:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\new_env\\lib\\socket.py:835\u001b[0m, in \u001b[0;36mcreate_connection\u001b[1;34m(address, timeout, source_address)\u001b[0m\n\u001b[0;32m    834\u001b[0m err \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m--> 835\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m res \u001b[38;5;129;01min\u001b[39;00m \u001b[43mgetaddrinfo\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhost\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mport\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mSOCK_STREAM\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m    836\u001b[0m     af, socktype, proto, canonname, sa \u001b[38;5;241m=\u001b[39m res\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\new_env\\lib\\socket.py:966\u001b[0m, in \u001b[0;36mgetaddrinfo\u001b[1;34m(host, port, family, type, proto, flags)\u001b[0m\n\u001b[0;32m    965\u001b[0m addrlist \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m--> 966\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m res \u001b[38;5;129;01min\u001b[39;00m \u001b[43m_socket\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetaddrinfo\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhost\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mport\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfamily\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mtype\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mproto\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflags\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m    967\u001b[0m     af, socktype, proto, canonname, sa \u001b[38;5;241m=\u001b[39m res\n",
      "\u001b[1;31mgaierror\u001b[0m: [Errno 11001] getaddrinfo failed",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mConnectError\u001b[0m                              Traceback (most recent call last)",
      "File \u001b[1;32m~\\anaconda3\\envs\\new_env\\lib\\site-packages\\httpx\\_transports\\default.py:69\u001b[0m, in \u001b[0;36mmap_httpcore_exceptions\u001b[1;34m()\u001b[0m\n\u001b[0;32m     68\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 69\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[0;32m     70\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\new_env\\lib\\site-packages\\httpx\\_transports\\default.py:233\u001b[0m, in \u001b[0;36mHTTPTransport.handle_request\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m    232\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m map_httpcore_exceptions():\n\u001b[1;32m--> 233\u001b[0m     resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_pool\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    235\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(resp\u001b[38;5;241m.\u001b[39mstream, typing\u001b[38;5;241m.\u001b[39mIterable)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\new_env\\lib\\site-packages\\httpcore\\_sync\\connection_pool.py:268\u001b[0m, in \u001b[0;36mConnectionPool.handle_request\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m    267\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresponse_closed(status)\n\u001b[1;32m--> 268\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc\n\u001b[0;32m    269\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\new_env\\lib\\site-packages\\httpcore\\_sync\\connection_pool.py:251\u001b[0m, in \u001b[0;36mConnectionPool.handle_request\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m    250\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 251\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mconnection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    252\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ConnectionNotAvailable:\n\u001b[0;32m    253\u001b[0m     \u001b[38;5;66;03m# The ConnectionNotAvailable exception is a special case, that\u001b[39;00m\n\u001b[0;32m    254\u001b[0m     \u001b[38;5;66;03m# indicates we need to retry the request on a new connection.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    258\u001b[0m     \u001b[38;5;66;03m# might end up as an HTTP/2 connection, but which actually ends\u001b[39;00m\n\u001b[0;32m    259\u001b[0m     \u001b[38;5;66;03m# up as HTTP/1.1.\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\new_env\\lib\\site-packages\\httpcore\\_sync\\connection.py:99\u001b[0m, in \u001b[0;36mHTTPConnection.handle_request\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m     98\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_connect_failed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m---> 99\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m exc\n\u001b[0;32m    100\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_connection\u001b[38;5;241m.\u001b[39mis_available():\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\new_env\\lib\\site-packages\\httpcore\\_sync\\connection.py:76\u001b[0m, in \u001b[0;36mHTTPConnection.handle_request\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m     75\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 76\u001b[0m     stream \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_connect\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     78\u001b[0m     ssl_object \u001b[38;5;241m=\u001b[39m stream\u001b[38;5;241m.\u001b[39mget_extra_info(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mssl_object\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\new_env\\lib\\site-packages\\httpcore\\_sync\\connection.py:124\u001b[0m, in \u001b[0;36mHTTPConnection._connect\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m Trace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconnect_tcp\u001b[39m\u001b[38;5;124m\"\u001b[39m, logger, request, kwargs) \u001b[38;5;28;01mas\u001b[39;00m trace:\n\u001b[1;32m--> 124\u001b[0m     stream \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_network_backend\u001b[38;5;241m.\u001b[39mconnect_tcp(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    125\u001b[0m     trace\u001b[38;5;241m.\u001b[39mreturn_value \u001b[38;5;241m=\u001b[39m stream\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\new_env\\lib\\site-packages\\httpcore\\_backends\\sync.py:213\u001b[0m, in \u001b[0;36mSyncBackend.connect_tcp\u001b[1;34m(self, host, port, timeout, local_address, socket_options)\u001b[0m\n\u001b[0;32m    212\u001b[0m         sock\u001b[38;5;241m.\u001b[39msetsockopt(\u001b[38;5;241m*\u001b[39moption)  \u001b[38;5;66;03m# pragma: no cover\u001b[39;00m\n\u001b[1;32m--> 213\u001b[0m     sock\u001b[38;5;241m.\u001b[39msetsockopt(socket\u001b[38;5;241m.\u001b[39mIPPROTO_TCP, socket\u001b[38;5;241m.\u001b[39mTCP_NODELAY, \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m SyncStream(sock)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\new_env\\lib\\contextlib.py:137\u001b[0m, in \u001b[0;36m_GeneratorContextManager.__exit__\u001b[1;34m(self, typ, value, traceback)\u001b[0m\n\u001b[0;32m    136\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 137\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgen\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mthrow\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtyp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraceback\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    138\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[0;32m    139\u001b[0m     \u001b[38;5;66;03m# Suppress StopIteration *unless* it's the same exception that\u001b[39;00m\n\u001b[0;32m    140\u001b[0m     \u001b[38;5;66;03m# was passed to throw().  This prevents a StopIteration\u001b[39;00m\n\u001b[0;32m    141\u001b[0m     \u001b[38;5;66;03m# raised inside the \"with\" statement from being suppressed.\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\new_env\\lib\\site-packages\\httpcore\\_exceptions.py:14\u001b[0m, in \u001b[0;36mmap_exceptions\u001b[1;34m(map)\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(exc, from_exc):\n\u001b[1;32m---> 14\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m to_exc(exc) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mexc\u001b[39;00m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "\u001b[1;31mConnectError\u001b[0m: [Errno 11001] getaddrinfo failed",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mConnectError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[49], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m co \u001b[38;5;241m=\u001b[39m cohere\u001b[38;5;241m.\u001b[39mClient(os\u001b[38;5;241m.\u001b[39menviron\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m2thOmTVyrX5uwYuSieF1AhVKxRwP3UuZxakIiXc3\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[0;32m      2\u001b[0m full_prompt\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHow are you?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m----> 3\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mco\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcommand-xlarge-nightly\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmessage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfull_prompt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m750\u001b[39;49m\n\u001b[0;32m      7\u001b[0m \u001b[43m)\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(response\u001b[38;5;241m.\u001b[39mtext)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\new_env\\lib\\site-packages\\cohere\\client.py:103\u001b[0m, in \u001b[0;36mexperimental_kwarg_decorator.<locals>._wrapped\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     98\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m check_kwarg(deprecated_kwarg, kwargs):\n\u001b[0;32m     99\u001b[0m     logger\u001b[38;5;241m.\u001b[39mwarning(\n\u001b[0;32m    100\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe `\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdeprecated_kwarg\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m` parameter is an experimental feature and may change in future releases.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    101\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTo suppress this warning, set `log_warning_experimental_features=False` when initializing the client.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    102\u001b[0m     )\n\u001b[1;32m--> 103\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\new_env\\lib\\site-packages\\cohere\\client.py:35\u001b[0m, in \u001b[0;36mvalidate_args.<locals>._wrapped\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_wrapped\u001b[39m(\u001b[38;5;241m*\u001b[39margs: typing\u001b[38;5;241m.\u001b[39mAny, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: typing\u001b[38;5;241m.\u001b[39mAny) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m typing\u001b[38;5;241m.\u001b[39mAny:\n\u001b[0;32m     34\u001b[0m     check_fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m---> 35\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m method(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\new_env\\lib\\site-packages\\cohere\\base_client.py:943\u001b[0m, in \u001b[0;36mBaseCohere.chat\u001b[1;34m(self, message, accepts, model, preamble, chat_history, conversation_id, prompt_truncation, connectors, search_queries_only, documents, citation_quality, temperature, max_tokens, max_input_tokens, k, p, seed, stop_sequences, frequency_penalty, presence_penalty, raw_prompting, return_prompt, tools, tool_results, force_single_step, response_format, safety_mode, request_options)\u001b[0m\n\u001b[0;32m    644\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mchat\u001b[39m(\n\u001b[0;32m    645\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    646\u001b[0m     \u001b[38;5;241m*\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    674\u001b[0m     request_options: typing\u001b[38;5;241m.\u001b[39mOptional[RequestOptions] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    675\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m NonStreamedChatResponse:\n\u001b[0;32m    676\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    677\u001b[0m \u001b[38;5;124;03m    Generates a text response to a user message.\u001b[39;00m\n\u001b[0;32m    678\u001b[0m \u001b[38;5;124;03m    To learn how to use the Chat API and RAG follow our [Text Generation guides](https://docs.cohere.com/docs/chat-api).\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    941\u001b[0m \u001b[38;5;124;03m    )\u001b[39;00m\n\u001b[0;32m    942\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 943\u001b[0m     _response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_client_wrapper\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhttpx_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    944\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mv1/chat\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    945\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mPOST\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    946\u001b[0m \u001b[43m        \u001b[49m\u001b[43mjson\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\n\u001b[0;32m    947\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmessage\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    948\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodel\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    949\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpreamble\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpreamble\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    950\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mchat_history\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert_and_respect_annotation_metadata\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    951\u001b[0m \u001b[43m                \u001b[49m\u001b[43mobject_\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchat_history\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mannotation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtyping\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mSequence\u001b[49m\u001b[43m[\u001b[49m\u001b[43mMessage\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdirection\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mwrite\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[0;32m    952\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    953\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mconversation_id\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mconversation_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    954\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mprompt_truncation\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprompt_truncation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    955\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mconnectors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert_and_respect_annotation_metadata\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    956\u001b[0m \u001b[43m                \u001b[49m\u001b[43mobject_\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconnectors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mannotation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtyping\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mSequence\u001b[49m\u001b[43m[\u001b[49m\u001b[43mChatConnector\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdirection\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mwrite\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[0;32m    957\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    958\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msearch_queries_only\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43msearch_queries_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    959\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdocuments\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mdocuments\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    960\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcitation_quality\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mcitation_quality\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    961\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtemperature\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    962\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmax_tokens\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    963\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmax_input_tokens\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_input_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    964\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mk\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    965\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mp\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mp\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    966\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mseed\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    967\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstop_sequences\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop_sequences\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    968\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfrequency_penalty\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrequency_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    969\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpresence_penalty\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpresence_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    970\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mraw_prompting\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mraw_prompting\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    971\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mreturn_prompt\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_prompt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    972\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtools\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert_and_respect_annotation_metadata\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    973\u001b[0m \u001b[43m                \u001b[49m\u001b[43mobject_\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mannotation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtyping\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mSequence\u001b[49m\u001b[43m[\u001b[49m\u001b[43mTool\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdirection\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mwrite\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[0;32m    974\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    975\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtool_results\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert_and_respect_annotation_metadata\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    976\u001b[0m \u001b[43m                \u001b[49m\u001b[43mobject_\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtool_results\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mannotation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtyping\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mSequence\u001b[49m\u001b[43m[\u001b[49m\u001b[43mToolResult\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdirection\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mwrite\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[0;32m    977\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    978\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mforce_single_step\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mforce_single_step\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    979\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mresponse_format\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert_and_respect_annotation_metadata\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    980\u001b[0m \u001b[43m                \u001b[49m\u001b[43mobject_\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresponse_format\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mannotation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mResponseFormat\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdirection\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mwrite\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[0;32m    981\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    982\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msafety_mode\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43msafety_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    983\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstream\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    984\u001b[0m \u001b[43m        \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    985\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\n\u001b[0;32m    986\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcontent-type\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mapplication/json\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    987\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mAccepts\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43maccepts\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43maccepts\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    988\u001b[0m \u001b[43m        \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    989\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    990\u001b[0m \u001b[43m        \u001b[49m\u001b[43momit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mOMIT\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    991\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    992\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    993\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;241m200\u001b[39m \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m _response\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m300\u001b[39m:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\new_env\\lib\\site-packages\\cohere\\core\\http_client.py:198\u001b[0m, in \u001b[0;36mHttpClient.request\u001b[1;34m(self, path, method, base_url, params, json, data, content, files, headers, request_options, retries, omit)\u001b[0m\n\u001b[0;32m    190\u001b[0m timeout \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    191\u001b[0m     request_options\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimeout_in_seconds\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    192\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m request_options \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m request_options\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimeout_in_seconds\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    193\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbase_timeout()\n\u001b[0;32m    194\u001b[0m )\n\u001b[0;32m    196\u001b[0m json_body, data_body \u001b[38;5;241m=\u001b[39m get_request_body(json\u001b[38;5;241m=\u001b[39mjson, data\u001b[38;5;241m=\u001b[39mdata, request_options\u001b[38;5;241m=\u001b[39mrequest_options, omit\u001b[38;5;241m=\u001b[39momit)\n\u001b[1;32m--> 198\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhttpx_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    199\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    200\u001b[0m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murllib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murljoin\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mbase_url\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m/\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    201\u001b[0m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mjsonable_encoder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    202\u001b[0m \u001b[43m        \u001b[49m\u001b[43mremove_none_from_dict\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    203\u001b[0m \u001b[43m            \u001b[49m\u001b[43m{\u001b[49m\n\u001b[0;32m    204\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbase_headers\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    205\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    206\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mrequest_options\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43madditional_headers\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrequest_options\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    207\u001b[0m \u001b[43m            \u001b[49m\u001b[43m}\u001b[49m\n\u001b[0;32m    208\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    209\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    210\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencode_query\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    211\u001b[0m \u001b[43m        \u001b[49m\u001b[43mjsonable_encoder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    212\u001b[0m \u001b[43m            \u001b[49m\u001b[43mremove_none_from_dict\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    213\u001b[0m \u001b[43m                \u001b[49m\u001b[43mremove_omit_from_dict\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    214\u001b[0m \u001b[43m                    \u001b[49m\u001b[43m{\u001b[49m\n\u001b[0;32m    215\u001b[0m \u001b[43m                        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    216\u001b[0m \u001b[43m                        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m    217\u001b[0m \u001b[43m                            \u001b[49m\u001b[43mrequest_options\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43madditional_query_parameters\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\n\u001b[0;32m    218\u001b[0m \u001b[43m                            \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrequest_options\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\n\u001b[0;32m    219\u001b[0m \u001b[43m                            \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\n\u001b[0;32m    220\u001b[0m \u001b[43m                        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    221\u001b[0m \u001b[43m                    \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    222\u001b[0m \u001b[43m                    \u001b[49m\u001b[43momit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    223\u001b[0m \u001b[43m                \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    224\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    225\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    226\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    227\u001b[0m \u001b[43m    \u001b[49m\u001b[43mjson\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mjson_body\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    228\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_body\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    229\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcontent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcontent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    230\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiles\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m    231\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconvert_file_dict_to_httpx_tuples\u001b[49m\u001b[43m(\u001b[49m\u001b[43mremove_omit_from_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mremove_none_from_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfiles\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43momit\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    232\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mfiles\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mand\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mfiles\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43momit\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    233\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\n\u001b[0;32m    234\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    235\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    236\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    238\u001b[0m max_retries: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m=\u001b[39m request_options\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmax_retries\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m0\u001b[39m) \u001b[38;5;28;01mif\u001b[39;00m request_options \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m    239\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _should_retry(response\u001b[38;5;241m=\u001b[39mresponse):\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\new_env\\lib\\site-packages\\httpx\\_client.py:827\u001b[0m, in \u001b[0;36mClient.request\u001b[1;34m(self, method, url, content, data, files, json, params, headers, cookies, auth, follow_redirects, timeout, extensions)\u001b[0m\n\u001b[0;32m    812\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(message, \u001b[38;5;167;01mDeprecationWarning\u001b[39;00m)\n\u001b[0;32m    814\u001b[0m request \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuild_request(\n\u001b[0;32m    815\u001b[0m     method\u001b[38;5;241m=\u001b[39mmethod,\n\u001b[0;32m    816\u001b[0m     url\u001b[38;5;241m=\u001b[39murl,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    825\u001b[0m     extensions\u001b[38;5;241m=\u001b[39mextensions,\n\u001b[0;32m    826\u001b[0m )\n\u001b[1;32m--> 827\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mauth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mauth\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\new_env\\lib\\site-packages\\httpx\\_client.py:914\u001b[0m, in \u001b[0;36mClient.send\u001b[1;34m(self, request, stream, auth, follow_redirects)\u001b[0m\n\u001b[0;32m    906\u001b[0m follow_redirects \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    907\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfollow_redirects\n\u001b[0;32m    908\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(follow_redirects, UseClientDefault)\n\u001b[0;32m    909\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m follow_redirects\n\u001b[0;32m    910\u001b[0m )\n\u001b[0;32m    912\u001b[0m auth \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_request_auth(request, auth)\n\u001b[1;32m--> 914\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_handling_auth\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    915\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    916\u001b[0m \u001b[43m    \u001b[49m\u001b[43mauth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mauth\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    917\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    918\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhistory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    919\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    920\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    921\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m stream:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\new_env\\lib\\site-packages\\httpx\\_client.py:942\u001b[0m, in \u001b[0;36mClient._send_handling_auth\u001b[1;34m(self, request, auth, follow_redirects, history)\u001b[0m\n\u001b[0;32m    939\u001b[0m request \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(auth_flow)\n\u001b[0;32m    941\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m--> 942\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_handling_redirects\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    943\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    944\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    945\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhistory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhistory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    946\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    947\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    948\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\new_env\\lib\\site-packages\\httpx\\_client.py:979\u001b[0m, in \u001b[0;36mClient._send_handling_redirects\u001b[1;34m(self, request, follow_redirects, history)\u001b[0m\n\u001b[0;32m    976\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_event_hooks[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrequest\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[0;32m    977\u001b[0m     hook(request)\n\u001b[1;32m--> 979\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_single_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    980\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    981\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_event_hooks[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresponse\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\new_env\\lib\\site-packages\\httpx\\_client.py:1015\u001b[0m, in \u001b[0;36mClient._send_single_request\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m   1010\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m   1011\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAttempted to send an async request with a sync Client instance.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1012\u001b[0m     )\n\u001b[0;32m   1014\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m request_context(request\u001b[38;5;241m=\u001b[39mrequest):\n\u001b[1;32m-> 1015\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mtransport\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1017\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response\u001b[38;5;241m.\u001b[39mstream, SyncByteStream)\n\u001b[0;32m   1019\u001b[0m response\u001b[38;5;241m.\u001b[39mrequest \u001b[38;5;241m=\u001b[39m request\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\new_env\\lib\\site-packages\\httpx\\_transports\\default.py:233\u001b[0m, in \u001b[0;36mHTTPTransport.handle_request\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m    220\u001b[0m req \u001b[38;5;241m=\u001b[39m httpcore\u001b[38;5;241m.\u001b[39mRequest(\n\u001b[0;32m    221\u001b[0m     method\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mmethod,\n\u001b[0;32m    222\u001b[0m     url\u001b[38;5;241m=\u001b[39mhttpcore\u001b[38;5;241m.\u001b[39mURL(\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    230\u001b[0m     extensions\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mextensions,\n\u001b[0;32m    231\u001b[0m )\n\u001b[0;32m    232\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m map_httpcore_exceptions():\n\u001b[1;32m--> 233\u001b[0m     resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pool\u001b[38;5;241m.\u001b[39mhandle_request(req)\n\u001b[0;32m    235\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(resp\u001b[38;5;241m.\u001b[39mstream, typing\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[0;32m    237\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m Response(\n\u001b[0;32m    238\u001b[0m     status_code\u001b[38;5;241m=\u001b[39mresp\u001b[38;5;241m.\u001b[39mstatus,\n\u001b[0;32m    239\u001b[0m     headers\u001b[38;5;241m=\u001b[39mresp\u001b[38;5;241m.\u001b[39mheaders,\n\u001b[0;32m    240\u001b[0m     stream\u001b[38;5;241m=\u001b[39mResponseStream(resp\u001b[38;5;241m.\u001b[39mstream),\n\u001b[0;32m    241\u001b[0m     extensions\u001b[38;5;241m=\u001b[39mresp\u001b[38;5;241m.\u001b[39mextensions,\n\u001b[0;32m    242\u001b[0m )\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\new_env\\lib\\contextlib.py:137\u001b[0m, in \u001b[0;36m_GeneratorContextManager.__exit__\u001b[1;34m(self, typ, value, traceback)\u001b[0m\n\u001b[0;32m    135\u001b[0m     value \u001b[38;5;241m=\u001b[39m typ()\n\u001b[0;32m    136\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 137\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgen\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mthrow\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtyp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraceback\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    138\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[0;32m    139\u001b[0m     \u001b[38;5;66;03m# Suppress StopIteration *unless* it's the same exception that\u001b[39;00m\n\u001b[0;32m    140\u001b[0m     \u001b[38;5;66;03m# was passed to throw().  This prevents a StopIteration\u001b[39;00m\n\u001b[0;32m    141\u001b[0m     \u001b[38;5;66;03m# raised inside the \"with\" statement from being suppressed.\u001b[39;00m\n\u001b[0;32m    142\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m exc \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m value\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\new_env\\lib\\site-packages\\httpx\\_transports\\default.py:86\u001b[0m, in \u001b[0;36mmap_httpcore_exceptions\u001b[1;34m()\u001b[0m\n\u001b[0;32m     83\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[0;32m     85\u001b[0m message \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(exc)\n\u001b[1;32m---> 86\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m mapped_exc(message) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mexc\u001b[39;00m\n",
      "\u001b[1;31mConnectError\u001b[0m: [Errno 11001] getaddrinfo failed"
     ]
    }
   ],
   "source": [
    "co = cohere.Client(os.environ.get(\"2thOmTVyrX5uwYuSieF1AhVKxRwP3UuZxakIiXc3\"))\n",
    "full_prompt=\"How are you?\"\n",
    "response = co.chat(\n",
    "    model=\"command-xlarge-nightly\",\n",
    "    message=full_prompt,\n",
    "    max_tokens=750\n",
    ")\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7c1db11-6bcc-4181-b9d0-1c5337fd2a96",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
