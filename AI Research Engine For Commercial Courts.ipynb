{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2e64cc2c-62ab-4b22-adca-842dcf2f5025",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\ASUS\\anaconda3\\envs\\new_env\\lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import nltk\n",
    "import docx\n",
    "import torch\n",
    "import queue\n",
    "import spacy\n",
    "import PyPDF2\n",
    "import joblib\n",
    "import cohere\n",
    "import logging\n",
    "import tempfile\n",
    "import warnings\n",
    "import threading\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tkinter as tk\n",
    "from tkinter import ttk\n",
    "from sklearn.svm import SVC\n",
    "from bs4 import BeautifulSoup\n",
    "from pdfminer.high_level import extract_text\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from nltk.tokenize.texttiling import TextTilingTokenizer\n",
    "from tkinter import filedialog, messagebox, Text, Scrollbar\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from transformers import pipeline, BertTokenizerFast, BertForTokenClassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e537ead9-8430-4967-ab7c-0af4f04d0b78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the dataset\n",
    "dataset_path = r\"C:\\Users\\ASUS\\OneDrive\\Documents\\Semester 9\\Mini Project\\Cases.csv\"\n",
    "cases_df = pd.read_csv(dataset_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ca27954d-f98e-4a5a-a639-13a44b59dbed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b092ba71e684316b2b79e87b3ef6321",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/3.51k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Initializing the SentenceTransformer model for semantic embedding\n",
    "embedding_model = SentenceTransformer('paraphrase-MiniLM-L6-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4c62fa44-e707-4651-b6cd-b62909589fde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the fine-tuned model and tokenizer\n",
    "model = BertForTokenClassification.from_pretrained('./ner_model')\n",
    "tokenizer = BertTokenizerFast.from_pretrained('./ner_model')\n",
    "ner_pipeline = pipeline(\"ner\", model=model, tokenizer=tokenizer, aggregation_strategy=\"simple\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e779f6c4-b7c8-4bb6-b083-b206842876db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing models and APIs\n",
    "co = cohere.Client(os.environ.get(\"2thOmTVyrX5uwYuSieF1AhVKxRwP3UuZxakIiXc3\"))\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"law-ai/InLegalBERT\")\n",
    "model = AutoModel.from_pretrained(\"law-ai/InLegalBERT\")\n",
    "tiling_tokenizer = TextTilingTokenizer()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "818651fe-6930-4ab0-b46a-633e5e8589c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_queue = queue.Queue()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7fedb07f-d951-421b-9b39-8ed75012a1e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Suppressing warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "096484c2-f11f-4b84-9d4d-c5a10fe92fc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def upload_file():\n",
    "    file_path = filedialog.askopenfilename(\n",
    "        title=\"Select Case File\",\n",
    "        filetypes=[(\"PDF Files\", \"*.pdf\"), (\"Word Documents\", \"*.docx\"), (\"Text Files\", \"*.txt\")]\n",
    "    )\n",
    "    if file_path:\n",
    "        threading.Thread(target=process_file, args=(file_path,), daemon=True).start()\n",
    "        start_progress_bar()\n",
    "    else:\n",
    "        messagebox.showinfo(\"Info\", \"No file selected.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d7bb8459-2b66-49ed-ba5d-9ee22f3a876c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_file(file_path):\n",
    "    try:\n",
    "        logging.info(f\"File Selected: {file_path}\")\n",
    "        file_label.config(text=f\"Selected File Path: {file_path}\")\n",
    "\n",
    "        if file_path.endswith(\".pdf\"):\n",
    "            content = extract_pdf(file_path)\n",
    "        elif file_path.endswith(\".docx\"):\n",
    "            content = extract_docx(file_path)\n",
    "        elif file_path.endswith(\".txt\"):\n",
    "            content = extract_txt(file_path)\n",
    "        else:\n",
    "            messagebox.showerror(\"Error\", \"Unsupported file format.\")\n",
    "            return\n",
    "        display_content(content)\n",
    "        entities = extract_entities(content)\n",
    "        unique_entities = list({(ent['word'], ent['entity_group']) for ent in entities})\n",
    "        print(\"Extracted Entities:\", unique_entities)\n",
    "\n",
    "        \n",
    "        search_query = \" \".join([ent[0] for ent in unique_entities])\n",
    "        case_links = search_indian_kanoon(search_query)\n",
    "        print(\"Found Case Links:\", case_links)\n",
    "\n",
    "        \n",
    "        for i in range(min(len(unique_entities), len(case_links))):\n",
    "            ent = unique_entities[i]\n",
    "            link = case_links[i]\n",
    "            print(f\"{ent[0]} : {link}\")\n",
    "\n",
    "        # Predict case details\n",
    "        preceding, legal_laws, result = predict_case_details(content)\n",
    "        print(f\"Predicted Preceding: {preceding}\")\n",
    "        print(f\"Predicted Legal Laws: {legal_laws}\")\n",
    "        print(f\"Predicted Result: {result}\")\n",
    "\n",
    "\n",
    "    except Exception as e:\n",
    "        logging.error(f\"An error occurred: {e}\")\n",
    "        messagebox.showerror(\"Error\", f\"An error occurred: {e}\")\n",
    "    \n",
    "    finally:\n",
    "        stop_progress_bar()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fc2f27e1-bbf6-4f5e-9b31-266f834073ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_gui():\n",
    "    try:\n",
    "        while not result_queue.empty():\n",
    "            content = result_queue.get()\n",
    "            display_content(content)\n",
    "    except Exception as e:\n",
    "        messagebox.showerror(\"Error\", f\"An error occurred while updating GUI: {e}\")\n",
    "    finally:\n",
    "        root.after(100, update_gui)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "752cf5f3-d33d-4f71-8e05-5c4e9d6b8c3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_pdf(pdf_path_var):\n",
    "    \"\"\"Open file dialog to select a PDF and display its path.\"\"\"\n",
    "    file_path = filedialog.askopenfilename(filetypes=[(\"PDF Files\", \"*.pdf\")])\n",
    "    print(f\"Selected file path: {file_path}\")  # Debugging step\n",
    "    \n",
    "    if file_path:  # Check if a file was selected\n",
    "        pdf_path_var.set(file_path)\n",
    "    else:\n",
    "        print(\"No file selected!\")  # Debugging step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1b2bcf5b-5e5a-4003-a1db-e08e964bfba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_text_from_pdf(pdf_path):\n",
    "    return extract_text(pdf_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "76196c6f-565a-442c-bd0e-ce4d3dd0f875",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_engine(pdf_path_var, query_entry, response_text):\n",
    "    pdf_path = pdf_path_var.get()\n",
    "    query = query_entry.get(\"1.0\", tk.END).strip()\n",
    "    \n",
    "    if not pdf_path or not query:\n",
    "        messagebox.showerror(\"Error\", \"Please upload a PDF and enter a query.\")\n",
    "        return\n",
    "\n",
    "    try:\n",
    "        response = process_pdf_and_generate_response(pdf_path, query)\n",
    "        response_text.delete(\"1.0\", tk.END)\n",
    "        response_text.insert(tk.END, response)\n",
    "    except Exception as e:\n",
    "        messagebox.showerror(\"Error\", str(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9b0c54ce-a731-420e-98e4-f1a8dcc1d7ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_pdf_and_generate_response(pdf_path, query): \n",
    "    \n",
    "    # Extract text from the PDF\n",
    "    document_text = extract_text_from_pdf(pdf_path)\n",
    "    \n",
    "    # Tokenize and get document embeddings\n",
    "    text_chunks = tiling_tokenizer.tokenize(document_text)\n",
    "    document_embeddings = get_bert_embeddings(text_chunks)\n",
    "    \n",
    "    prompt = f\"You are an AI-driven research engine for commercial courts. Given the legal document: '{document_text[:2000]}', answer the query: '{query}'\"\n",
    "    response = generate_response(prompt, document_embeddings)\n",
    "    \n",
    "    # Check if the query mentions predictions or related cases\n",
    "    if \"prediction\" in query.lower() or \"preceding\" in query.lower() or \"legal_laws\" in query.lower() or \"result\" in query.lower():\n",
    "        predictions = predict_case_details(document_text)\n",
    "        response += \"\\n\\nPredictions: \" + str(predictions)\n",
    "    \n",
    "    if \"related cases\" in query.lower() or \"similar cases\" in query.lower():\n",
    "        related_cases = search_indian_kanoon(query)\n",
    "        response += \"\\n\\nRelated Cases: \" + str(related_cases)\n",
    "    \n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8ab0f512-6c11-4a1b-8755-0492796297c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_response(prompt, embeddings):\n",
    "    aggregated_embedding = np.mean([np.mean(embed) for embed in embeddings])\n",
    "    embedding_str = f\"Embedding summary: {aggregated_embedding:.2f}\"\n",
    "    full_prompt = f\"{embedding_str}\\n\\n{prompt}\"\n",
    "    try:\n",
    "        response = co.chat(\n",
    "            model=\"command-xlarge-nightly\",\n",
    "            message=full_prompt,\n",
    "            max_tokens=750\n",
    "        )\n",
    "        return response.text.strip()\n",
    "    except cohere.error.CohereError as e:\n",
    "        return f\"An error occurred: {str(e)}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9d92070c-333e-4185-9c5a-1213d5a344ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bert_embeddings(texts):\n",
    "    embeddings_list = []\n",
    "    for text in texts:\n",
    "        inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, max_length=512)\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**inputs)\n",
    "        embeddings = outputs.last_hidden_state[:, 0, :].squeeze().numpy()\n",
    "        embeddings_list.append(embeddings)\n",
    "    return embeddings_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d0aa129d-17e0-4e7c-bb38-1bc9abf11cdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def open_research_page():\n",
    "    # Root window\n",
    "    root = tk.Tk()\n",
    "    root.title(\"AI Research Engine for Legal Documents\")\n",
    "    root.geometry(\"850x700\")\n",
    "    root.configure(bg=\"#4CAF50\")\n",
    "\n",
    "    # Fonts\n",
    "    title_font = (\"Arial\", 18, \"bold\")\n",
    "    label_font = (\"Arial\", 12)\n",
    "    button_font = (\"Arial\", 11)\n",
    "\n",
    "    # Frames\n",
    "    title_frame = tk.Frame(root, bg=\"#4CAF50\", height=60)\n",
    "    title_frame.pack(fill=tk.X)\n",
    "\n",
    "    content_frame = tk.Frame(root, bg=\"#f5f5f5\", padx=20, pady=20)\n",
    "    content_frame.pack(fill=tk.BOTH, expand=True)\n",
    "\n",
    "    footer_frame = tk.Frame(root, bg=\"#4CAF50\", height=40)\n",
    "    footer_frame.pack(fill=tk.X)\n",
    "\n",
    "    # Title Label\n",
    "    title_label = tk.Label(\n",
    "        title_frame,\n",
    "        text=\"AI-Driven Research Engine for Commercial Courts\",\n",
    "        font=title_font,\n",
    "        bg=\"#4CAF50\",\n",
    "        fg=\"#ffffff\"\n",
    "    )\n",
    "    title_label.pack(pady=10)\n",
    "\n",
    "    # File Upload Section\n",
    "    pdf_path_var = tk.StringVar()\n",
    "    file_frame = tk.LabelFrame(content_frame, text=\"Upload Document\", font=label_font, bg=\"#f5f5f5\", padx=10, pady=10)\n",
    "    file_frame.pack(fill=\"x\", pady=10)\n",
    "\n",
    "    file_entry = ttk.Entry(file_frame, textvariable=pdf_path_var, width=60, state='readonly')\n",
    "    file_entry.grid(row=0, column=0, padx=5, pady=5)\n",
    "\n",
    "    browse_button = ttk.Button(file_frame, text=\"Browse\", command=lambda: select_pdf(pdf_path_var))\n",
    "    browse_button.grid(row=0, column=1, padx=5, pady=5)\n",
    "\n",
    "    # Query Input Section\n",
    "    query_frame = tk.LabelFrame(content_frame, text=\"Enter Query\", font=label_font, bg=\"#f5f5f5\", padx=10, pady=10)\n",
    "    query_frame.pack(fill=\"x\", pady=10)\n",
    "\n",
    "    query_entry = Text(query_frame, height=5, wrap=tk.WORD, font=(\"Arial\", 10))\n",
    "    query_entry.pack(fill=\"x\", padx=5, pady=5)\n",
    "\n",
    "    # Run Button\n",
    "    run_button = ttk.Button(content_frame, text=\"Generate Response\", command=lambda: run_engine(pdf_path_var, query_entry, response_text))\n",
    "    run_button.pack(pady=10)\n",
    "\n",
    "    # Response Display Section\n",
    "    response_frame = tk.LabelFrame(content_frame, text=\"Response\", font=label_font, bg=\"#f5f5f5\", padx=10, pady=10)\n",
    "    response_frame.pack(fill=\"both\", expand=True, pady=10)\n",
    "\n",
    "    response_text = Text(response_frame, wrap=tk.WORD, font=(\"Arial\", 10), height=15)\n",
    "    response_text.pack(fill=\"both\", expand=True, padx=5, pady=5)\n",
    "\n",
    "    response_scrollbar = Scrollbar(response_frame, command=response_text.yview)\n",
    "    response_scrollbar.pack(side=tk.RIGHT, fill=tk.Y)\n",
    "    response_text.config(yscrollcommand=response_scrollbar.set)\n",
    "\n",
    "    # Footer Label\n",
    "    footer_label = tk.Label(\n",
    "        footer_frame,\n",
    "        text=\"© 2024 AI Research Engine\",\n",
    "        font=(\"Arial\", 10),\n",
    "        bg=\"#4CAF50\",\n",
    "        fg=\"#ffffff\"\n",
    "    )\n",
    "    footer_label.pack(pady=10)\n",
    "\n",
    "    # Main loop to run the Tkinter application\n",
    "    root.mainloop()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "055ef8b2-7f8c-4f9f-bf7c-9c4c82d497f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_content(content):\n",
    "    def start_research():\n",
    "        open_research_page()\n",
    "        \n",
    "    def show_predictions():\n",
    "        # Predict case details only when the button/key is pressed\n",
    "        preceding, legal_laws, result = predict_case_details(content)\n",
    "        predictions_summary = f\"Preceding Case:\\n{preceding}\\n\\nLegal Laws:\\n{legal_laws}\\n\\nResult:\\n{result}\\n\"\n",
    "\n",
    "        predictions_window = tk.Toplevel(content_window)\n",
    "        predictions_window.title(\"Case Predictions\")\n",
    "        predictions_area = Text(predictions_window, wrap='word')\n",
    "        predictions_area.insert('1.0', predictions_summary)\n",
    "        predictions_area.config(state='disabled')\n",
    "        predictions_area.pack(expand=True, fill='both')\n",
    "    \n",
    "    content_window = tk.Toplevel()\n",
    "    content_window.title(\"Extracted Content\")\n",
    "    text_area = Text(content_window, wrap='word')\n",
    "    text_area.insert('1.0', \"Extracted Content:\\n\\n\" + content + \"\\n\\n\")\n",
    "    text_area.config(state='disabled')\n",
    "    text_area.pack(expand=True, fill='both')\n",
    "    content_window.geometry(\"600x500\")\n",
    "    \n",
    "    # Button to show predictions\n",
    "    predict_btn = tk.Button(content_window, text=\"Show Predictions\", command=show_predictions, bg=\"#4CAF50\", fg=\"white\", font=(\"Arial\", 12))\n",
    "    predict_btn.pack(pady=10)\n",
    "    \n",
    "    # Bind the 'p' key to show predictions\n",
    "    content_window.bind('<p>', lambda event: show_predictions())\n",
    "    \n",
    "    # Button to start research\n",
    "    research_btn = tk.Button(content_window, text=\"Start Research\", command=start_research, bg=\"#008CBA\", fg=\"white\", font=(\"Arial\", 12))\n",
    "    research_btn.pack(pady=10)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d4e90c9b-66f5-4b6b-a1f1-cc71c6ea5a5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_pdf(file_path):\n",
    "    print(f\"Processing PDF: {file_path}\")\n",
    "    content = \"\"\n",
    "    try:\n",
    "        with open(file_path, \"rb\") as file:\n",
    "            reader = PyPDF2.PdfReader(file)\n",
    "            for page in reader.pages:\n",
    "                text = page.extract_text()\n",
    "                if text:\n",
    "                    content += text + \"\\n\"\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing PDF: {e}\")\n",
    "    return content.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4b436275-0733-4b7c-a763-a2147af12bb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_docx(file_path):\n",
    "    print(f\"Processing DOCX: {file_path}\")\n",
    "    content = \"\"\n",
    "    try:\n",
    "        doc = docx.Document(file_path)\n",
    "        for paragraph in doc.paragraphs:\n",
    "            content += paragraph.text + \"\\n\"\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing DOCX: {e}\")\n",
    "    return content.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d2939833-afd9-4a6c-a9b4-70e803745012",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_txt(file_path):\n",
    "    print(f\"Processing TXT: {file_path}\")\n",
    "    content = \"\"\n",
    "    try:\n",
    "        with open(file_path, 'r', encoding='utf-8') as file:\n",
    "            content = file.read()\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing TXT: {e}\")\n",
    "    return content.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "04685771-8499-41d1-8ca9-9905df31b2d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_entities(text):\n",
    "    try:\n",
    "        entities = ner_pipeline(text)\n",
    "        return entities\n",
    "    except Exception as e:\n",
    "        print(f\"Error extracting entities: {e}\")\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f88cf765-6d22-4956-aa0d-759575aab2b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_indian_kanoon(query_text):\n",
    "    query_embedding = embedding_model.encode([query_text])\n",
    "\n",
    "    case_descriptions = cases_df['Case_Title'].tolist()\n",
    "    case_embeddings = embedding_model.encode(case_descriptions)\n",
    "\n",
    "    similarities = cosine_similarity(query_embedding, case_embeddings)\n",
    "\n",
    "    top_n = 5\n",
    "    top_n_indices = similarities[0].argsort()[-top_n:][::-1]\n",
    "\n",
    "    case_matches = []\n",
    "    for idx in top_n_indices:\n",
    "            case_matches.append({\n",
    "                'Case_Title': cases_df.iloc[idx]['Case_Title'],\n",
    "                'Similarity': similarities[0][idx]\n",
    "        })\n",
    "    return case_matches\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f58d3834-ca88-4654-8aa5-cfc4d171c17d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model training complete and saved!\n"
     ]
    }
   ],
   "source": [
    "# Combine relevant columns for features\n",
    "cases_df['Combined_Text'] = cases_df[['Case_Title', 'Citation', 'Court', \n",
    "                                      'Judgement_Date', 'Judges', 'Petitioner',\n",
    "                                      'Respondent', 'Bench']].apply(lambda x: ' '.join(x.astype(str)), axis=1)\n",
    "\n",
    "# Define features (X) and targets (y)\n",
    "X = cases_df['Combined_Text']\n",
    "y = cases_df[['Preceding', 'Legal_Laws', 'Result']]\n",
    "\n",
    "# TF-IDF vectorization\n",
    "tfidf = TfidfVectorizer(max_features=5000)\n",
    "X_vectorized = tfidf.fit_transform(X)\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_vectorized, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# MultiOutputClassifier with Random Forest\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "multi_rf = MultiOutputClassifier(rf_model)\n",
    "multi_rf.fit(X_train, y_train)\n",
    "\n",
    "# Save the trained model and vectorizer\n",
    "joblib.dump(multi_rf, 'random_forest_model.pkl')\n",
    "joblib.dump(tfidf, 'tfidf_vectorizer.pkl')\n",
    "\n",
    "print(\"Model training complete and saved!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "83500942-c0a5-4ce0-a73a-a3835cb795db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_case_details(content):\n",
    "    \"\"\"\n",
    "    Predict Preceding, Legal Laws, and Result based on uploaded content.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        multi_rf = joblib.load('random_forest_model.pkl')\n",
    "        tfidf = joblib.load('tfidf_vectorizer.pkl')\n",
    "        content_vector = tfidf.transform([content])\n",
    "        predictions = multi_rf.predict(content_vector)\n",
    "        preceding, legal_laws, result = predictions[0]\n",
    "\n",
    "        return preceding, legal_laws, result\n",
    "    except Exception as e:\n",
    "        print(f\"Prediction error: {e}\")\n",
    "        return None, None, None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b968ef9a-98ee-4c88-bc43-379fcbf13548",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_query_details(query_text):\n",
    "    \"\"\"\n",
    "    Predict Precedings, Legal Laws, and Result based on the search query.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Load model and vectorizer\n",
    "        multi_rf = joblib.load('random_forest_model.pkl')\n",
    "        tfidf = joblib.load('tfidf_vectorizer.pkl')\n",
    "\n",
    "        # Vectorize the query text\n",
    "        query_vector = tfidf.transform([query_text])\n",
    "\n",
    "        # Predict\n",
    "        predictions = multi_rf.predict(query_vector)\n",
    "        preceding, legal_laws, result = predictions[0]\n",
    "\n",
    "        return preceding, legal_laws, result\n",
    "    except Exception as e:\n",
    "        print(f\"Prediction error for query: {e}\")\n",
    "        return None, None, None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "aa05adf6-75e1-44a3-83ff-001e0ac778aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize_case_titles():\n",
    "    case_titles = cases_df['Case_Title'].tolist()\n",
    "\n",
    "    # Use SentenceTransformer to get embeddings\n",
    "    model = SentenceTransformer('paraphrase-MiniLM-L6-v2')\n",
    "    case_vectors = model.encode(case_titles)\n",
    "\n",
    "    return case_titles, case_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "67e69508-df48-4338-9b4c-545d41f82508",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_related_cases(query, case_titles, case_vectors, top_n=5):\n",
    "    # Vectorize the query using SentenceTransformer\n",
    "    model = SentenceTransformer('paraphrase-MiniLM-L6-v2')\n",
    "    query_vector = model.encode([query])\n",
    "\n",
    "    # Perform KNN search\n",
    "    knn = NearestNeighbors(n_neighbors=top_n, metric='cosine')\n",
    "    knn.fit(case_vectors)\n",
    "    distances, indices = knn.kneighbors(query_vector)\n",
    "\n",
    "    # Get the most similar case titles based on the indices\n",
    "    related_cases = [case_titles[idx] for idx in indices[0]]\n",
    "    return related_cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "596cbe5b-2cf7-4c0c-9068-0641d193fdf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def start_progress_bar():\n",
    "    progress_bar.pack(pady=10)\n",
    "    progress_bar.start(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d6634991-25e9-46c4-94c1-c0fa4a5eec4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stop_progress_bar():\n",
    "    progress_bar.stop()\n",
    "    progress_bar.pack_forget()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2e4dcaff-f9c0-4f1a-a89c-27597cc35594",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_entities():\n",
    "    query = search_entry.get()\n",
    "    if query:\n",
    "        threading.Thread(target=process_search, args=(query,), daemon=True).start()\n",
    "        start_progress_bar()\n",
    "    else:\n",
    "        messagebox.showinfo(\"Info\", \"Please enter a search term.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2a981596-90c0-470c-9fbc-3a64f238c6c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_search_results(case_links, query_text):\n",
    "    results_window = tk.Toplevel()\n",
    "    results_window.title(\"Search Results\")\n",
    "    results_window.geometry(\"600x500\")\n",
    "    text_area = Text(results_window, wrap='word')\n",
    "    content = \"Top Similar Cases Based on Semantic Search:\\n\\n\"\n",
    "    for link in case_links:\n",
    "        content += f\"{link['Case_Title']} (Similarity: {link['Similarity']:.2f})\\n\"\n",
    "    text_area.insert('1.0', content)\n",
    "    text_area.config(state='disabled')\n",
    "    text_area.pack(expand=True, fill='both')\n",
    "\n",
    "    # Add Predict button\n",
    "    predict_button = tk.Button(\n",
    "        results_window,\n",
    "        text=\"Predict\",\n",
    "        command=lambda: show_predictions_window(query_text), \n",
    "        bg=\"#4CAF50\", \n",
    "        fg=\"white\", \n",
    "        font=(\"Arial\", 12)\n",
    "    )\n",
    "    predict_button.pack(pady=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ac4ca224-d78e-4078-b279-e2e6cdb51179",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_predictions_window(query_text):\n",
    "    try:\n",
    "        preceding, legal_laws, result = predict_query_details(query_text)\n",
    "        predictions_window = tk.Toplevel()\n",
    "        predictions_window.title(\"Query Predictions\")\n",
    "        predictions_window.geometry(\"600x400\")\n",
    "\n",
    "        text_area = Text(predictions_window, wrap='word')\n",
    "        predictions_summary = (\n",
    "            f\"Search Query Predictions:\\n\\n\"\n",
    "            f\"Preceding Case:\\n{preceding if preceding else 'N/A'}\\n\\n\"\n",
    "            f\"Legal Laws:\\n{legal_laws if legal_laws else 'N/A'}\\n\\n\"\n",
    "            f\"Result:\\n{result if result else 'N/A'}\\n\"\n",
    "        )\n",
    "        text_area.insert('1.0', predictions_summary)\n",
    "        text_area.config(state='disabled')\n",
    "        text_area.pack(expand=True, fill='both')\n",
    "\n",
    "    except Exception as e:\n",
    "        messagebox.showerror(\"Error\", f\"An error occurred while displaying predictions: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "baa606ca-72b0-4941-8ab7-98014fbea907",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_search(query):\n",
    "    try:\n",
    "        case_links = search_indian_kanoon(query)\n",
    "        preceding, legal_laws, result = predict_query_details(query)\n",
    "        print(f\"Predicted Preceding: {preceding}\")\n",
    "        print(f\"Predicted Legal Laws: {legal_laws}\")\n",
    "        print(f\"Predicted Result: {result}\")\n",
    "        display_search_results(case_links,query)\n",
    "    except Exception as e:\n",
    "        messagebox.showerror(\"Error\", f\"An error occurred during the search: {e}\")\n",
    "    finally:\n",
    "        stop_progress_bar()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a9d3dccc-ed91-4e2b-8316-2dd706f4f05c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the Tkinter GUI\n",
    "root = tk.Tk()\n",
    "root.title(\"File Upload and Content Extractor\")\n",
    "root.geometry(\"600x400\")\n",
    "root.config(bg=\"#f0f0f0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "aff8a90d-589e-4e62-bd8c-51ec599dceb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "instruction_label = tk.Label(root, text=\"Upload the case file as .pdf, .docx or .txt\",\n",
    "                               bg=\"#f0f0f0\", font=(\"Arial\", 12))\n",
    "instruction_label.pack(pady=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "808e5ee0-de9d-4008-bed1-09c0ca7b5573",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entry for search term\n",
    "search_entry = tk.Entry(root, width=50, font=(\"Arial\", 12))\n",
    "search_entry.pack(pady=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d910e457-84ab-4572-ae97-c38768dc3edf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Search button\n",
    "search_btn = tk.Button(root, text=\"Search\", command=search_entities, width=20, bg=\"#4CAF50\", fg=\"white\", font=(\"Arial\", 12))\n",
    "search_btn.pack(pady=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ec211e0a-8440-4002-a7d4-ecfa00ecf523",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Frame for the upload button\n",
    "frame = tk.Frame(root, bg=\"#ffffff\", bd=2, relief=tk.GROOVE)\n",
    "frame.pack(pady=20, padx=10, fill='both', expand=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "fefeea23-505f-4484-8daf-19f7e5b79dc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "upload_btn = tk.Button(frame, text=\"Upload File\", command=upload_file, width=20, bg=\"#4CAF50\", fg=\"white\", font=(\"Arial\", 12))\n",
    "upload_btn.pack(pady=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f4b3d78e-35db-4b22-b572-521114210843",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label to display selected file path\n",
    "file_label = tk.Label(frame, text=\"Selected File Path: \", bg=\"#f0f0f0\", font=(\"Arial\", 10))\n",
    "file_label.pack(pady=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e2f48468-4f7c-4a96-872c-5d3f137ee8b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Progress bar (initially hidden)\n",
    "progress_bar = ttk.Progressbar(root, orient=\"horizontal\", mode=\"indeterminate\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "77ec9eb4-7a8e-47df-9f37-daf497a05efd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start the Tkinter event loop\n",
    "root.mainloop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "34cb334c-6223-433c-bd80-199518f42d91",
   "metadata": {},
   "outputs": [],
   "source": [
    "def open_research_page():\n",
    "    import warnings\n",
    "    warnings.filterwarnings('ignore')\n",
    "\n",
    "    import os\n",
    "    import tempfile\n",
    "    import tkinter as tk\n",
    "    from tkinter import filedialog, messagebox, Text, Scrollbar\n",
    "    from tkinter import ttk  # For themed widgets\n",
    "\n",
    "    import torch\n",
    "    import numpy as np\n",
    "    import cohere\n",
    "    import spacy\n",
    "    from nltk.tokenize import word_tokenize\n",
    "    from nltk import pos_tag\n",
    "    from pdfminer.high_level import extract_text\n",
    "    from nltk.tokenize.texttiling import TextTilingTokenizer\n",
    "\n",
    "    from transformers import AutoTokenizer, AutoModel\n",
    "\n",
    "    import nltk\n",
    "\n",
    "    # Initialize models and APIs\n",
    "    co = cohere.Client(os.environ.get(\"2thOmTVyrX5uwYuSieF1AhVKxRwP3UuZxakIiXc3\"))\n",
    "    nlp = spacy.load(\"en_core_web_sm\")\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\"law-ai/InLegalBERT\")\n",
    "    model = AutoModel.from_pretrained(\"law-ai/InLegalBERT\")\n",
    "    tiling_tokenizer = TextTilingTokenizer()\n",
    "\n",
    "    # Functions\n",
    "    def generate_response(prompt, embeddings):\n",
    "        aggregated_embedding = np.mean([np.mean(embed) for embed in embeddings])\n",
    "        embedding_str = f\"Embedding summary: {aggregated_embedding:.2f}\"\n",
    "        full_prompt = f\"{embedding_str}\\n\\n{prompt}\"\n",
    "        \n",
    "        try:\n",
    "            response = co.chat(\n",
    "                model=\"command-xlarge-nightly\",\n",
    "                message=full_prompt,\n",
    "                max_tokens=750\n",
    "            )\n",
    "            return response.text.strip()\n",
    "        except cohere.error.CohereError as e:\n",
    "            return f\"An error occurred: {str(e)}\"\n",
    "\n",
    "    def extract_text_from_pdf(pdf_path):\n",
    "        return extract_text(pdf_path)\n",
    "\n",
    "    def get_bert_embeddings(texts):\n",
    "        embeddings_list = []\n",
    "        for text in texts:\n",
    "            inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, max_length=512)\n",
    "            with torch.no_grad():\n",
    "                outputs = model(**inputs)\n",
    "            embeddings = outputs.last_hidden_state[:, 0, :].squeeze().numpy()\n",
    "            embeddings_list.append(embeddings)\n",
    "        return embeddings_list\n",
    "\n",
    "    def process_pdf_and_generate_response(pdf_path, query):\n",
    "        document_text = extract_text_from_pdf(pdf_path)\n",
    "        text_chunks = tiling_tokenizer.tokenize(document_text)\n",
    "        document_embeddings = get_bert_embeddings(text_chunks)\n",
    "        \n",
    "        prompt = f\"You are an AI-driven research engine for commercial courts. Given the legal document: '{document_text[:2000]}', answer the query: '{query}'\"\n",
    "        response = generate_response(prompt, document_embeddings)\n",
    "        return response\n",
    "\n",
    "    def select_pdf():\n",
    "        file_path = filedialog.askopenfilename(filetypes=[(\"PDF Files\", \"*.pdf\")])\n",
    "        pdf_path_var.set(file_path)\n",
    "\n",
    "    def run_engine():\n",
    "        pdf_path = pdf_path_var.get()\n",
    "        query = query_entry.get(\"1.0\", tk.END).strip()\n",
    "        if not pdf_path or not query:\n",
    "            messagebox.showerror(\"Error\", \"Please upload a PDF and enter a query.\")\n",
    "            return\n",
    "        \n",
    "        try:\n",
    "            response = process_pdf_and_generate_response(pdf_path, query)\n",
    "            response_text.delete(\"1.0\", tk.END)\n",
    "            response_text.insert(tk.END, response)\n",
    "        except Exception as e:\n",
    "            messagebox.showerror(\"Error\", str(e))\n",
    "\n",
    "    # Tkinter GUI\n",
    "    root = tk.Tk()\n",
    "    root.title(\"AI Research Engine for Legal Documents\")\n",
    "    root.geometry(\"850x700\")\n",
    "    root.configure(bg=\"#4CAF50\")\n",
    "\n",
    "    # Fonts\n",
    "    title_font = (\"Arial\", 18, \"bold\")\n",
    "    label_font = (\"Arial\", 12)\n",
    "    button_font = (\"Arial\", 11)\n",
    "\n",
    "    # Frames\n",
    "    title_frame = tk.Frame(root, bg=\"#4CAF50\", height=60)\n",
    "    title_frame.pack(fill=tk.X)\n",
    "\n",
    "    content_frame = tk.Frame(root, bg=\"#f5f5f5\", padx=20, pady=20)\n",
    "    content_frame.pack(fill=tk.BOTH, expand=True)\n",
    "\n",
    "    footer_frame = tk.Frame(root, bg=\"#4CAF50\", height=40)\n",
    "    footer_frame.pack(fill=tk.X)\n",
    "\n",
    "    # Title\n",
    "    title_label = tk.Label(\n",
    "        title_frame,\n",
    "        text=\"AI-Driven Research Engine for Commercial Courts\",\n",
    "        font=title_font,\n",
    "        bg=\"#4CAF50\",\n",
    "        fg=\"#ffffff\"\n",
    "    )\n",
    "    title_label.pack(pady=10)\n",
    "\n",
    "    # File Upload\n",
    "    pdf_path_var = tk.StringVar()\n",
    "    file_frame = tk.LabelFrame(content_frame, text=\"Upload Document\", font=label_font, bg=\"#f5f5f5\", padx=10, pady=10)\n",
    "    file_frame.pack(fill=\"x\", pady=10)\n",
    "\n",
    "    file_entry = ttk.Entry(file_frame, textvariable=pdf_path_var, width=60, state='readonly')\n",
    "    file_entry.grid(row=0, column=0, padx=5, pady=5)\n",
    "\n",
    "    browse_button = ttk.Button(file_frame, text=\"Browse\", command=select_pdf)\n",
    "    browse_button.grid(row=0, column=1, padx=5, pady=5)\n",
    "\n",
    "    # Query Input\n",
    "    query_frame = tk.LabelFrame(content_frame, text=\"Enter Query\", font=label_font, bg=\"#f5f5f5\", padx=10, pady=10)\n",
    "    query_frame.pack(fill=\"x\", pady=10)\n",
    "\n",
    "    query_entry = Text(query_frame, height=5, wrap=tk.WORD, font=(\"Arial\", 10))\n",
    "    query_entry.pack(fill=\"x\", padx=5, pady=5)\n",
    "\n",
    "    # Run Button\n",
    "    run_button = ttk.Button(content_frame, text=\"Generate Response\", command=run_engine)\n",
    "    run_button.pack(pady=10)\n",
    "\n",
    "    # Response Display\n",
    "    response_frame = tk.LabelFrame(content_frame, text=\"Response\", font=label_font, bg=\"#f5f5f5\", padx=10, pady=10)\n",
    "    response_frame.pack(fill=\"both\", expand=True, pady=10)\n",
    "\n",
    "    response_text = Text(response_frame, wrap=tk.WORD, font=(\"Arial\", 10), height=15)\n",
    "    response_text.pack(fill=\"both\", expand=True, padx=5, pady=5)\n",
    "\n",
    "    response_scrollbar = Scrollbar(response_frame, command=response_text.yview)\n",
    "    response_scrollbar.pack(side=tk.RIGHT, fill=tk.Y)\n",
    "    response_text.config(yscrollcommand=response_scrollbar.set)\n",
    "\n",
    "    # Footer\n",
    "    footer_label = tk.Label(\n",
    "        footer_frame,\n",
    "        text=\"© 2024 AI Research Engine\",\n",
    "        font=(\"Arial\", 10),\n",
    "        bg=\"#4CAF50\",\n",
    "        fg=\"#ffffff\"\n",
    "    )\n",
    "    footer_label.pack(pady=10)\n",
    "\n",
    "    # Mainloop\n",
    "    root.mainloop()\n",
    "open_research_page()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7c1db11-6bcc-4181-b9d0-1c5337fd2a96",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
